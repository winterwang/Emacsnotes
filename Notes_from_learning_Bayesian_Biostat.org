#+TITLE:     Bayesian Biostatistics Learning note
#+AUTHOR:   [[https://wangcc.me][Chaochen Wang]]
#+EMAIL:     chaochen@wangcc.me
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:t f:t inline:t num:t
#+OPTIONS: timestamp:t title:t toc:t todo:t |:t


* Chapter 2 Bayes theorem: computing the posterior distribution

** the binary version of Bayes theorem

$$
p(\theta = 1 | y = 1) = 
\frac{p(y = 1 | \theta = 1)\times p(\theta=1)}
{p(y = 1 | \theta = 1)\times p(\theta = 1) +
p(y = 1 | \theta  = 0)\times p(\theta = 0)}
$$

In the above exporession, 

- $p(\theta = 1)(p(\theta = 0))$ represents the prevalence (1 -
  prevalence) of a disease. But in general it is called the /prior/
  probability that $\theta = 1 (\theta = 0)$.

- The probability $p(y = 1 | \theta = 1)$ describes the probability
  that a positive test is obtained, given that $\theta = 1$. It is the
  **likelihood** for $\theta = 1$ with a positive test.

- Finally, $p(\theta = 1 | y = 1)$ is the probability that an
  individual is diseased given observing a positive test. This
  probability is called the /posterior/ probability that is derived
  from combining the prior information and the observed data.

$$
p(\theta | y) = \frac{p(y | \theta)p(\theta)}{p(y)}
$$

** Probability in a Bayesian context 

1) For an "honest" coin, the classical probablity that a coin will
   show heads when tossed up is 0.5. This **probability** has a
   /long-run frequency meaning/. **"objective"**
2) Suppose that you don't believe that there exist honest coins then
   you might give it a probability of 0.6. This kind of probability
   expresses your /personal belief/ and is typically an example of
   /Bayesian probability/. **"subjective"**
