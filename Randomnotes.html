<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-11-16 Sat 16:44 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Random notes by Org-mode 2019-02</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="[[https://wangcc.me][Chaochen Wang]]Chaochen Wang" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Random notes by Org-mode 2019-02</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org3ab3589">1. Therneau, Terry, Cynthia CrowsonとElizabeth Atkinson. 「Using Time Dependent Covariates and Time Dependent Coeﬃcients in the Cox Model」, 日付なし, 27.</a>
<ul>
<li>
<ul>
<li><a href="#org5927a25">1.0.1. When subjects have multiple events, then the rows for the events are correlated within subject and a cluster variance is needed.</a></li>
<li><a href="#orgd11daf6">1.0.2. When a subject appears in overlapping intervals. This however is almost always a data error, since it corresponds to two copies of the subject being present in the same strata at the same time, e.g. she could meet herself at a party.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org4413d85">2. pdf-tools (https://github.com/politza/pdf-tools) within the Emacs is good for annoation and reading pdf files</a></li>
<li><a href="#orgb579d24">3. CFA</a>
<ul>
<li><a href="#org4db9f9c">3.1. Factor Rotation (P27-)</a>
<ul>
<li><a href="#orgf16a358">3.1.1. Once the appropriate number of factors has been determined, the extracted factors are rotated, to foster their <b><b>intepretaibility</b></b>.</a></li>
<li><a href="#orga57309c">3.1.2. For any given multiple-factor model, there exist an infinite number of equally good-fitting solutions (each represented by a different factor loading matrix)</a></li>
<li><a href="#orgbba2272">3.1.3. In applied research, factor loadings greater than or equal to 0.30 or 0.40 are often interpreted as salient (i.e. the indicator is meaningfully related to a primary or secondary factor).</a></li>
<li><a href="#org1c01978">3.1.4. For models that contain two or more factors, rotation is conducted to produce a solution with <b><b>the best simple structure.</b></b></a></li>
<li><a href="#org27ea769">3.1.5. It is important to emphasize that rotation does not alter the fit of the solution. Rather, factor rotation is a mathematical transformation that is undertaken to foster interpretability by maximizing larger factor loadings closer to one and minimizing smaller factor loadings closer to zero.</a></li>
<li><a href="#org8a80c88">3.1.6. Constraining factors to be uncorrelated in CFA will typically result in poor model fit.</a></li>
<li><a href="#orga97b14a">3.1.7. Conceptually, a factor score is the score that would have been observed for a person if it had been possible to measure the factor directly.</a></li>
<li><a href="#orgcc09525">3.1.8. Specifically, a correlation matrix is used as input in EFA, and both the factors and indicators are completely standardized regression coefficients.</a></li>
<li><a href="#org38404ce">3.1.9. Although CFA also produces a completely standardized solution, much of the analysis does not standardize the latent or observed variables.</a></li>
<li><a href="#org0dc71ad">3.1.10. A covariance can be calculated by multiplying the correlation of the two indicators by their standard deviations, i.e., \(COV_{xy} = r_{xy}SD_xSD_y\)</a></li>
<li><a href="#org5fb455f">3.1.11. SEM methodogolists often express a strong preference for reporting unstandardized solutions because the analysis itself is based on unstandardized variables, and completely standardized values are potentially misleading.</a></li>
<li><a href="#org2fcdef7">3.1.12. For instance, the true nature of the variance and relationships among indicators and factors can be masked when these variables have been standardized; when the original matric of variables is expressed in meaningful units, unstandardized estimates more clearly convey the importance or substantive significance of the effects.</a></li>
<li><a href="#orge02ffcc">3.1.13. All indicators in EFA freely load on all factors, and the solution is rotated to maximize the magnitude of primary loadings and minimize the magnitude of cross-loadings.</a></li>
<li><a href="#org5ff29e8">3.1.14. Factor rotation does not apply to CFA. This is because the identification restrictions associated with CFA are achieved in part by <b><b>fixing most or all indicator cross-loadings to zero</b></b>.</a></li>
<li><a href="#orgafb879d">3.1.15. The communality is the sum of squared factor loadings for a given indicator across all factors.</a></li>
</ul>
</li>
<li><a href="#org487c108">3.2. Parameters of a CFA model</a></li>
<li><a href="#orga146c52">3.3. CFA model indentification (P53)</a></li>
<li><a href="#org950b350">3.4. Specification and interpretation of CFA models (P115)</a></li>
</ul>
</li>
<li><a href="#org182bb83">4. Onyx: A graphical interface for Structural Equation Modeling</a></li>
<li><a href="#org005b9d6">5. Org-mode-tutorials: http://pragmaticemacs.com/org-mode-tutorials/</a></li>
<li><a href="#org5282706">6. Illustrating the impact of a time-varying covarate with and extended Kaplan-Meier Estimator</a></li>
<li><a href="#org285c63a">7. Rajkomar, Alvin, Jeffrey DeanとIsaac Kohane. 「Machine Learning in Medicine」. New England Journal of Medicine 380, no. 14 (2019年4月4日): 1347–58. https://doi.org/10.1056/NEJMra1814259.</a></li>
<li><a href="#orgcb595b9">8. Joint Models for Longitudinal and Time-to-Event Data with Applications in R</a>
<ul>
<li><a href="#orgb3ae9d9">8.1. An important inherent characteristic of these medical conditions is their dynamic nature. That is, the rate of progression is not only different from patient to patient but also dynamically changes in time for the same patient.</a></li>
<li><a href="#org48dfe09">8.2. However, despite this flexibility the extended Cox model is not appropriate when the time-dependent covariates are of endogenous nature. This is because the extended Cox model assume that time-dependent covariates are predictable processes, measured without error, and have their complete path fully specified.</a></li>
<li><a href="#org6147d45">8.3. It is not reasonable to assume that the biomarker remains constant between follow-up visits, especially because these can be several months apart.</a></li>
</ul>
</li>
<li><a href="#orgf32799e">9. Evidence and evolution</a></li>
<li><a href="#org99ced4c">10. Gabadinho, A., Ritschard, G., Mueller, N. S. &amp; Studer, M. Analyzing and Visualizing State Sequences in R with TraMineR. Journal of Statistical Software 40, 1–37 (2011).</a>
<ul>
<li><a href="#org2aa9d42">10.1. central concept of <b>state sequence object</b></a></li>
</ul>
</li>
<li><a href="#orgfe2933c">11. naniar package; dataset name: riskfactor</a></li>
<li><a href="#org2e79690">12. supervised learning</a>
<ul>
<li><a href="#org4a6d882">12.1. Mean absolute error (MAE)</a></li>
<li><a href="#org62fce88">12.2. Mean squared error (MSE)</a></li>
<li><a href="#org0ea5167">12.3. \(R^2\)</a></li>
<li><a href="#orgf63d35f">12.4. AUC</a></li>
<li><a href="#org87c5605">12.5. 例外：目的変数に外れ値がある；ラベルに偏りがある</a></li>
<li><a href="#org0111589">12.6. regulation 正則化</a>
<ul>
<li><a href="#org80e9e35">12.6.1. L1 (Lasso)</a></li>
<li><a href="#orgae88966">12.6.2. L2 (Ridge)</a></li>
<li><a href="#org48bc57b">12.6.3. Random forest</a></li>
<li><a href="#org94b06ed">12.6.4. 注意</a></li>
</ul>
</li>
<li><a href="#org0774009">12.7. kNN 近傍法</a></li>
<li><a href="#org78a0a56">12.8. 決定木 decision tree</a></li>
<li><a href="#org9e88e23">12.9. ランダムフォレスト</a></li>
<li><a href="#org38e9c06">12.10. ブースティング（GBM）</a></li>
<li><a href="#org74672f9">12.11. SVM support vector machine</a></li>
<li><a href="#orgeb35ae0">12.12. カーネルSVM</a></li>
<li><a href="#org09fe772">12.13. neuro network</a>
<ul>
<li><a href="#org9732e06">12.13.1. 活性化関数 ReLU関数</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org11cbdbd">13. Unsupervised learning</a>
<ul>
<li><a href="#orgb45a337">13.1. データの潜在的パターンを抽出：クラスタリング、次元圧縮</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org3ab3589" class="outline-2">
<h2 id="org3ab3589"><span class="section-number-2">1</span> Therneau, Terry, Cynthia CrowsonとElizabeth Atkinson. 「Using Time Dependent Covariates and Time Dependent Coeﬃcients in the Cox Model」, 日付なし, 27.</h2>
<div class="outline-text-2" id="text-1">
<ol class="org-ol">
<li>Page 4: One common question with this data setup is whether we need to worry about correlated data, since a given subject has multiple observations. The answer is no, we do not. The reason is that this representation is simply a programming trick. The likelihood equations at any time point use only one copy of any subject, the program picks out the correct row of data at each times. There are two exceptions to this rule:</li>
</ol>
</div>

<div id="outline-container-org5927a25" class="outline-4">
<h4 id="org5927a25"><span class="section-number-4">1.0.1</span> When subjects have multiple events, then the rows for the events are correlated within subject and a cluster variance is needed.</h4>
</div>
<div id="outline-container-orgd11daf6" class="outline-4">
<h4 id="orgd11daf6"><span class="section-number-4">1.0.2</span> When a subject appears in overlapping intervals. This however is almost always a data error, since it corresponds to two copies of the subject being present in the same strata at the same time, e.g. she could meet herself at a party.</h4>
</div>
</div>

<div id="outline-container-org4413d85" class="outline-2">
<h2 id="org4413d85"><span class="section-number-2">2</span> pdf-tools (<a href="https://github.com/politza/pdf-tools">https://github.com/politza/pdf-tools</a>) within the Emacs is good for annoation and reading pdf files</h2>
</div>
<div id="outline-container-orgb579d24" class="outline-2">
<h2 id="orgb579d24"><span class="section-number-2">3</span> CFA</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org4db9f9c" class="outline-3">
<h3 id="org4db9f9c"><span class="section-number-3">3.1</span> Factor Rotation (P27-)</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-orgf16a358" class="outline-4">
<h4 id="orgf16a358"><span class="section-number-4">3.1.1</span> Once the appropriate number of factors has been determined, the extracted factors are rotated, to foster their <b><b>intepretaibility</b></b>.</h4>
</div>

<div id="outline-container-orga57309c" class="outline-4">
<h4 id="orga57309c"><span class="section-number-4">3.1.2</span> For any given multiple-factor model, there exist an infinite number of equally good-fitting solutions (each represented by a different factor loading matrix)</h4>
</div>

<div id="outline-container-orgbba2272" class="outline-4">
<h4 id="orgbba2272"><span class="section-number-4">3.1.3</span> In applied research, factor loadings greater than or equal to 0.30 or 0.40 are often interpreted as salient (i.e. the indicator is meaningfully related to a primary or secondary factor).</h4>
</div>

<div id="outline-container-org1c01978" class="outline-4">
<h4 id="org1c01978"><span class="section-number-4">3.1.4</span> For models that contain two or more factors, rotation is conducted to produce a solution with <b><b>the best simple structure.</b></b></h4>
</div>

<div id="outline-container-org27ea769" class="outline-4">
<h4 id="org27ea769"><span class="section-number-4">3.1.5</span> It is important to emphasize that rotation does not alter the fit of the solution. Rather, factor rotation is a mathematical transformation that is undertaken to foster interpretability by maximizing larger factor loadings closer to one and minimizing smaller factor loadings closer to zero.</h4>
</div>

<div id="outline-container-org8a80c88" class="outline-4">
<h4 id="org8a80c88"><span class="section-number-4">3.1.6</span> Constraining factors to be uncorrelated in CFA will typically result in poor model fit.</h4>
</div>

<div id="outline-container-orga97b14a" class="outline-4">
<h4 id="orga97b14a"><span class="section-number-4">3.1.7</span> Conceptually, a factor score is the score that would have been observed for a person if it had been possible to measure the factor directly.</h4>
</div>

<div id="outline-container-orgcc09525" class="outline-4">
<h4 id="orgcc09525"><span class="section-number-4">3.1.8</span> Specifically, a correlation matrix is used as input in EFA, and both the factors and indicators are completely standardized regression coefficients.</h4>
</div>

<div id="outline-container-org38404ce" class="outline-4">
<h4 id="org38404ce"><span class="section-number-4">3.1.9</span> Although CFA also produces a completely standardized solution, much of the analysis does not standardize the latent or observed variables.</h4>
</div>

<div id="outline-container-org0dc71ad" class="outline-4">
<h4 id="org0dc71ad"><span class="section-number-4">3.1.10</span> A covariance can be calculated by multiplying the correlation of the two indicators by their standard deviations, i.e., \(COV_{xy} = r_{xy}SD_xSD_y\)</h4>
</div>

<div id="outline-container-org5fb455f" class="outline-4">
<h4 id="org5fb455f"><span class="section-number-4">3.1.11</span> SEM methodogolists often express a strong preference for reporting unstandardized solutions because the analysis itself is based on unstandardized variables, and completely standardized values are potentially misleading.</h4>
</div>


<div id="outline-container-org2fcdef7" class="outline-4">
<h4 id="org2fcdef7"><span class="section-number-4">3.1.12</span> For instance, the true nature of the variance and relationships among indicators and factors can be masked when these variables have been standardized; when the original matric of variables is expressed in meaningful units, unstandardized estimates more clearly convey the importance or substantive significance of the effects.</h4>
</div>

<div id="outline-container-orge02ffcc" class="outline-4">
<h4 id="orge02ffcc"><span class="section-number-4">3.1.13</span> All indicators in EFA freely load on all factors, and the solution is rotated to maximize the magnitude of primary loadings and minimize the magnitude of cross-loadings.</h4>
</div>

<div id="outline-container-org5ff29e8" class="outline-4">
<h4 id="org5ff29e8"><span class="section-number-4">3.1.14</span> Factor rotation does not apply to CFA. This is because the identification restrictions associated with CFA are achieved in part by <b><b>fixing most or all indicator cross-loadings to zero</b></b>.</h4>
</div>

<div id="outline-container-orgafb879d" class="outline-4">
<h4 id="orgafb879d"><span class="section-number-4">3.1.15</span> The communality is the sum of squared factor loadings for a given indicator across all factors.</h4>
</div>
</div>
<div id="outline-container-org487c108" class="outline-3">
<h3 id="org487c108"><span class="section-number-3">3.2</span> Parameters of a CFA model</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Factor loadings are the regression slopes for predicting the indicators from the latent variable. 
</p>
</div>
</div>

<div id="outline-container-orga146c52" class="outline-3">
<h3 id="orga146c52"><span class="section-number-3">3.3</span> CFA model indentification (P53)</h3>
<div class="outline-text-3" id="text-3-3">
<p>
In order to estimate the parameters in CFA, the measurement model must be identified. A model is identified if, on the basis of known information (i.e., the variances and covariances in the sample input matrix).
</p>

<p>
In the first and by far the more popular method, the researcher fixes the metric of the latent variable to be the same as one of its indicators "marker or reference indicator".
</p>

<p>
In the seconde method, the variance of the latent variable is fixed to a specific value, usually 1.00. However, this method is used less often than the marker indicator approach. 
</p>

<p>
The former strategy produces an unstandardized solution (in addition to a completely standardized solution), which is useful for several purposes, such as tests of measurement invariance across groups and evaluations of scale reliability.
</p>

<p>
Unlike just-identified models, overidentified models rarely fit the data perfectly (i.e., a perfectly fitting model is one whose parameter estimates recreate the data perfectly). 
</p>

<p>
Specification of a model to have at least 0 df is a necessary but not sufficient condition for indentification.
</p>

<p>
For these and other reasons, methodologists recommend that latent variables be defined by a minimum of three indicators to avoid this possible source of underidentification. 
</p>

<p>
By far, the fitting function most widely used in applied CFA research (and SEM in general) is ML (maximum likelihood). The fitting function that is minimized in ML is:
</p>

<p>
\[
F_{\text{ML}} = ln|S| - ln|\Sigma| + \text{trace}[(S)(\Sigma^{-1})] - p
\]
</p>

<p>
where, \(|S|\) is the determinant of the input variance-covariance matrix, \(|\Sigma|\) is the predicted variance-covariance matrix, \(p\) is the order of the input matrix (i.e. the number of input indicators); and \(ln\) is the natural logarithm.
</p>

<p>
The underlying principle of ML estimation in CFA is to find the model parameter estimates that maximize the probability of observing the available data if the data are collected from the same population again.
</p>

<p>
Some key assumption of ML are that 
</p>

<p>
(1) The sample size is large (asymptotic); 
(2) The indicators have been measured on continuous scales (i.e., approximate interval-level data);
(3) The distribution of the indicators is multivariate normal. 
</p>

<p>
The latter two assumptions apply to indicators of latent variables, not to other observed measures that may exist in the analysis, such as nominal variables that serve as covariates. Although the actual parameter estimates (factor loadings) may not be affected, non-normality in ML analysis can result in biased standard errors (and hence faulty significance tests) and a poorly behaved \(\chi^2\) test of overall model fit. 
</p>

<p>
Thus in the case of non-normal, continuous indicators, it is better to use a different estimator, such as ML with robust standard errors and \(\chi^2\) (MLM) or the MLR estimator in the Mplus program. MLM and MLR provide the same parameter estimates as ML, but both the model \(\chi^2\) and standard errors of the parameter estimates are corrected for non-normality in large samples. 
</p>
</div>
</div>

<div id="outline-container-org950b350" class="outline-3">
<h3 id="org950b350"><span class="section-number-3">3.4</span> Specification and interpretation of CFA models (P115)</h3>
<div class="outline-text-3" id="text-3-4">
<p>
In CFA models where there are no cross-loading indicators, the complete standardized factor loading can be interpreted as the correlation between the indicator and the factor. Accordingly, squaring the completed standardized factor loading provides the proportion of <b><b>variance of the indicator</b></b> that is explained by the factor &#x2013; that is a communality. 
</p>
</div>
</div>
</div>

<div id="outline-container-org182bb83" class="outline-2">
<h2 id="org182bb83"><span class="section-number-2">4</span> Onyx: A graphical interface for Structural Equation Modeling</h2>
<div class="outline-text-2" id="text-4">
<p>
<a href="http://onyx.brandmaier.de/what-is-onyx/">http://onyx.brandmaier.de/what-is-onyx/</a>
</p>
</div>
</div>

<div id="outline-container-org005b9d6" class="outline-2">
<h2 id="org005b9d6"><span class="section-number-2">5</span> Org-mode-tutorials: <a href="http://pragmaticemacs.com/org-mode-tutorials/">http://pragmaticemacs.com/org-mode-tutorials/</a></h2>
</div>

<div id="outline-container-org5282706" class="outline-2">
<h2 id="org5282706"><span class="section-number-2">6</span> Illustrating the impact of a time-varying covarate with and extended Kaplan-Meier Estimator</h2>
<div class="outline-text-2" id="text-6">
<p>
For example it may be reasonable to assume that the risk of ESRD (end stage renal disease) is a function of the patient's current value of serum creatinine and, conditional on that value, is not related to any previous values. 
</p>

<p>
&#x2026; 
</p>

<p>
One special type of time-varying covariate deserves attention. During follow-up certain intervening events may occur which can irreversibly alter the patient's risk of the endpoint of interest. For example, the patient might suffer a stroke or permanently discontinue study medication. The covariates representing these intervening events can only take the value 0 or 1, and an individual's covariate value cannot change from 1 to 0 during the course of the trial. 
</p>

<p>
&#x2026; 
</p>

<p>
By accounting for the time-varying nature of the covariates, the result should be an illustration of the expected probability of having had an event, as a function of time, for hypothetical cohorts of patients with constant covariate values over time. 
</p>

<p>
&#x2026; 
</p>
</div>

<ol class="org-ol">
<li><a id="org203194f"></a>\(n\) = the total sample size<br /></li>
<li><a id="orgf914935"></a>\(Y_i\) = the follow-up time<br /></li>
<li><a id="orge7f1ea1"></a>\(\delta_i\) = an event indicator (1 if the patient had an event at time \(Y_i\))<br /></li>
<li><a id="orgf52cacc"></a>\(i\) is a patient indicator (patient ID)<br />
<div class="outline-text-5" id="text-6-0-0-4">
<p>
&#x2026;
</p>

<p>
Approach 1. The Final Covariate Value (comes from the Heart Outcomes Prevention Evaluation, HOPE study). This approach is clearly inconsistent with the Cox regression model, since the Cox model makes use of the patients' covariate value at each event time. 
</p>

<p>
&#x2026; 
</p>


<p>
The extended Kaplan-Meier estimator recommended here simply updates the cohorts at each event time. 
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org285c63a" class="outline-2">
<h2 id="org285c63a"><span class="section-number-2">7</span> Rajkomar, Alvin, Jeffrey DeanとIsaac Kohane. 「Machine Learning in Medicine」. New England Journal of Medicine 380, no. 14 (2019年4月4日): 1347–58. <a href="https://doi.org/10.1056/NEJMra1814259">https://doi.org/10.1056/NEJMra1814259</a>.</h2>
<div class="outline-text-2" id="text-7">
<p>
Machine learning is not just a new tool, such as a new drug or medical device. Rather, it is the fundamental technology required to meaningfully process data that exceed the capacity of the human brain to comprehend. 
</p>
</div>
</div>

<div id="outline-container-orgcb595b9" class="outline-2">
<h2 id="orgcb595b9"><span class="section-number-2">8</span> Joint Models for Longitudinal and Time-to-Event Data with Applications in R</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-orgb3ae9d9" class="outline-3">
<h3 id="orgb3ae9d9"><span class="section-number-3">8.1</span> An important inherent characteristic of these medical conditions is their dynamic nature. That is, the rate of progression is not only different from patient to patient but also dynamically changes in time for the same patient.</h3>
</div>

<div id="outline-container-org48dfe09" class="outline-3">
<h3 id="org48dfe09"><span class="section-number-3">8.2</span> However, despite this flexibility the extended Cox model is not appropriate when the time-dependent covariates are of endogenous nature. This is because the extended Cox model assume that time-dependent covariates are predictable processes, measured without error, and have their complete path fully specified.</h3>
</div>

<div id="outline-container-org6147d45" class="outline-3">
<h3 id="org6147d45"><span class="section-number-3">8.3</span> It is not reasonable to assume that the biomarker remains constant between follow-up visits, especially because these can be several months apart.</h3>
</div>
</div>


<div id="outline-container-orgf32799e" class="outline-2">
<h2 id="orgf32799e"><span class="section-number-2">9</span> Evidence and evolution</h2>
<div class="outline-text-2" id="text-9">
<p>
With out a difference in likelihood, the posterior probability must have the same value as the prior; the observation has not affected your degree of belief. (P15)
</p>

<p>
Confirmation does not mean proving true and disconfirmation does not mean proving false; confirmation and disconfirmation does mean only that an observation should increase or reduce your confidence that H is true. 
</p>

<p>
Bayesian confirmation and disconfirmation involve comparisons of probabilities; they say nothing about the <b><b>absolute values</b></b> of any probability.
</p>

<p>
likelihoods are often independent of priors. (P18)
</p>

<p>
A central thesis of Bayesianism is: <b><b>no propabilities out without any probabilities in.</b></b> 
</p>

<p>
The effect of assigning equal priors is that all the real work is done by the likelihoods; if the priors are equal, the hypothesis of greatest likelihood must also be the hypothesis that has the greatest posterior probability. 
</p>


<p>
Bayesian philophers often see Bayesianism as analogous to deductive logic in this respect. Deductive logic does not tell you what you should take your premises to be; logic is solely in the business of giving advice on what follows from them. <b><b>So the fact that priors and likelihoods are sometimes subjective is just a fact of life in which we all have to deal.</b></b> 
</p>


<p>
(P37) &#x2026; we just need to recognize that the ordinary words "support" and "favouring" sometimes need to be understood within a Bayesian framework in which it is the probabilities of hypotheses that are under discussion;&#x2026;
</p>

<p>
(P43) &#x2026; As simple and familiar as this fact about multiple independent testimonies is, it is important to bear in mind that there is no rule written in Heaven that separate pieces of evidence must be independent.
</p>

<p>
(P48) &#x2026; I said that Bayesians hold that science is in the business of determining which theories are probably true while frequentists hold that this is not at all what science is about. 
</p>

<p>
(P51) Dawkins, Dembski, and Morris have all made the same mistake. It isn't that they have glommed on to the wrong cutoff. The problem is deeper: <b>There is no such cutoff.</b> Probabilistic modus tollens is an incorrect form of inference. 
</p>

<p>
(P52) &#x2026; a central idea in the likelihoodist theory of evidence: judgements about evidential meaning are essentially constrastive. To decide whether an observation is evidence against H, you need to know what the alternative hypotheses are; to test a hypothesis requires testing it against alternatives. 
</p>

<p>
(P57) &#x2026; This is the patterns of reasoning that Sherlock Holmes endorses in <b>The Sign of Four</b> where Sir Arthur Conan Doyle has his hero say that "when you have eliminated the impossible, whatever remains, however improbable, mush be the truth."
</p>
</div>
</div>

<div id="outline-container-org99ced4c" class="outline-2">
<h2 id="org99ced4c"><span class="section-number-2">10</span> Gabadinho, A., Ritschard, G., Mueller, N. S. &amp; Studer, M. Analyzing and Visualizing State Sequences in R with TraMineR. Journal of Statistical Software 40, 1–37 (2011).</h2>
<div class="outline-text-2" id="text-10">
</div>
<div id="outline-container-org2aa9d42" class="outline-3">
<h3 id="org2aa9d42"><span class="section-number-3">10.1</span> central concept of <b>state sequence object</b></h3>
<div class="outline-text-3" id="text-10-1">
<p>
<span class="timestamp-wrapper"><span class="timestamp">&lt;2019-11-16 Sat 14:42&gt; </span></span> 
</p>
</div>
</div>
</div>
<div id="outline-container-orgfe2933c" class="outline-2">
<h2 id="orgfe2933c"><span class="section-number-2">11</span> naniar package; dataset name: riskfactor</h2>
</div>




<div id="outline-container-org2e79690" class="outline-2">
<h2 id="org2e79690"><span class="section-number-2">12</span> supervised learning</h2>
<div class="outline-text-2" id="text-12">
</div>
<div id="outline-container-org4a6d882" class="outline-3">
<h3 id="org4a6d882"><span class="section-number-3">12.1</span> Mean absolute error (MAE)</h3>
<div class="outline-text-3" id="text-12-1">
<p>
\[
MAE= \frac{\sum_{i=1}^N|y - \hat{y} |}{N}
\]
</p>
</div>
</div>

<div id="outline-container-org62fce88" class="outline-3">
<h3 id="org62fce88"><span class="section-number-3">12.2</span> Mean squared error (MSE)</h3>
</div>

<div id="outline-container-org0ea5167" class="outline-3">
<h3 id="org0ea5167"><span class="section-number-3">12.3</span> \(R^2\)</h3>
</div>

<div id="outline-container-orgf63d35f" class="outline-3">
<h3 id="orgf63d35f"><span class="section-number-3">12.4</span> AUC</h3>
</div>

<div id="outline-container-org87c5605" class="outline-3">
<h3 id="org87c5605"><span class="section-number-3">12.5</span> 例外：目的変数に外れ値がある；ラベルに偏りがある</h3>
</div>

<div id="outline-container-org0111589" class="outline-3">
<h3 id="org0111589"><span class="section-number-3">12.6</span> regulation 正則化</h3>
<div class="outline-text-3" id="text-12-6">
</div>
<div id="outline-container-org80e9e35" class="outline-4">
<h4 id="org80e9e35"><span class="section-number-4">12.6.1</span> L1 (Lasso)</h4>
<div class="outline-text-4" id="text-12-6-1">
<p>
\[
E(\mathbf{w}) + \lambda\sum_{i=1}^K|w_i|
\]
</p>
</div>
</div>

<div id="outline-container-orgae88966" class="outline-4">
<h4 id="orgae88966"><span class="section-number-4">12.6.2</span> L2 (Ridge)</h4>
<div class="outline-text-4" id="text-12-6-2">
<p>
\[
E(\mathbf{w}) + \frac{\lambda}{2}\sum_{i=1}^K|w_i|^2
\]
</p>
</div>
</div>

<div id="outline-container-org48bc57b" class="outline-4">
<h4 id="org48bc57b"><span class="section-number-4">12.6.3</span> Random forest</h4>
</div>

<div id="outline-container-org94b06ed" class="outline-4">
<h4 id="org94b06ed"><span class="section-number-4">12.6.4</span> 注意</h4>
<div class="outline-text-4" id="text-12-6-4">
</div>
<ol class="org-ol">
<li><a id="orgbbb0528"></a>正則化で消えてしまった変数は関連が全くないわけではない（あくまでも今回の予測に使わなかった；変数の関連の強さや有意性を判定する手段ではない）<br /></li>
<li><a id="org1867d1d"></a>正則化を強くかけすぎると逆に予測精度が下がることがある。under fitting<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org0774009" class="outline-3">
<h3 id="org0774009"><span class="section-number-3">12.7</span> kNN 近傍法</h3>
<div class="outline-text-3" id="text-12-7">
<p>
近くにあるK個のサンプルのラベルを参照して、多いラベルを正解とする。
単純で学習不要、理論的に一致性が高い。
欠点：
</p>
</div>
</div>

<div id="outline-container-org78a0a56" class="outline-3">
<h3 id="org78a0a56"><span class="section-number-3">12.8</span> 決定木 decision tree</h3>
<div class="outline-text-3" id="text-12-8">
<p>
利点：解釈しやすい、外れ値に強い、変数の依存関係を考慮できる。
欠点：変数の使われ方がほぼ一意的にきまってしまう；木が浅いと精度が悪く、深いと過学習しやすい
</p>
</div>
</div>

<div id="outline-container-org9e88e23" class="outline-3">
<h3 id="org9e88e23"><span class="section-number-3">12.9</span> ランダムフォレスト</h3>
<div class="outline-text-3" id="text-12-9">
<p>
決定木をランダムにたくさん集めて、多数決で最終結果を決める方法
</p>

<p>
利点：外れ値に強い；変数の依存関係を考慮できる；特定の変数のみに影響を受けすぎない
欠点：回帰（数値予測）に使うときは、学習データの範囲でしか予測できない。（外挿できない）
</p>
</div>
</div>

<div id="outline-container-org38e9c06" class="outline-3">
<h3 id="org38e9c06"><span class="section-number-3">12.10</span> ブースティング（GBM）</h3>
<div class="outline-text-3" id="text-12-10">
<p>
予測を間違えたものに、より着目して次の学習を行う機会学習手法
</p>

<p>
利点：間違えた部分に特化して学習するので、精度が上がりやすい
欠点：そもそも予測できないデータを学習させると過学習することがある
</p>
</div>
</div>

<div id="outline-container-org74672f9" class="outline-3">
<h3 id="org74672f9"><span class="section-number-3">12.11</span> SVM support vector machine</h3>
<div class="outline-text-3" id="text-12-11">
<p>
境界線と近くの点の距離（マージン）が最大になるような境界線を見つける
</p>

<p>
利点：マージンを指標にすることで過学習しにくい
欠点：線形データのみ；学習が非効率（大規模データに弱い）；変数選択・正則化は別に考える必要がある。
</p>
</div>
</div>

<div id="outline-container-orgeb35ae0" class="outline-3">
<h3 id="orgeb35ae0"><span class="section-number-3">12.12</span> カーネルSVM</h3>
<div class="outline-text-3" id="text-12-12">
<p>
もともと線形分離できないデータを別の特徴区間に写像することで線形分離可能にする方法
</p>

<p>
利点：カーネルトリックにより計算自体は低次元で行える；非線形データにも使える。
欠点：カーネルの選び方が難しい；変数選択・正則化は別に考える必要がある。
</p>
</div>
</div>

<div id="outline-container-org09fe772" class="outline-3">
<h3 id="org09fe772"><span class="section-number-3">12.13</span> neuro network</h3>
<div class="outline-text-3" id="text-12-13">
<p>
人間の脳神経回路を模倣したネットワークによって学習を行う方法
利点：人間の脳と挙動が近いので、脳科学で得られたアイディアを取り込める
欠点：２−３層のネットワークだとあまり複雑な問題は解けない；パラメータが大量にあるため過学習に陥ることも
</p>
</div>

<div id="outline-container-org9732e06" class="outline-4">
<h4 id="org9732e06"><span class="section-number-4">12.13.1</span> 活性化関数 ReLU関数</h4>
</div>
</div>
</div>

<div id="outline-container-org11cbdbd" class="outline-2">
<h2 id="org11cbdbd"><span class="section-number-2">13</span> Unsupervised learning</h2>
<div class="outline-text-2" id="text-13">
</div>
<div id="outline-container-orgb45a337" class="outline-3">
<h3 id="orgb45a337"><span class="section-number-3">13.1</span> データの潜在的パターンを抽出：クラスタリング、次元圧縮</h3>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: <a href="https://wangcc.me">Chaochen Wang</a></p>
<p class="email">Email: <a href="mailto:chaochen@wangcc.me">chaochen@wangcc.me</a></p>
<p class="date">Created: 2019-11-16 Sat 16:44</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
